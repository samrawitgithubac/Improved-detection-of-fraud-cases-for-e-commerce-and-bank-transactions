{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP Explainability (Task 3)\n",
        "\n",
        "This notebook explains the **best Task 2 model** using SHAP:\n",
        "\n",
        "- Global explanations: SHAP summary plot (top features)\n",
        "- Local explanations (3 examples):\n",
        "  - True Positive (TP): correctly detected fraud\n",
        "  - False Positive (FP): legitimate transaction flagged as fraud\n",
        "  - False Negative (FN): missed fraud\n",
        "\n",
        "### Prereqs\n",
        "\n",
        "1) Run Task 2 first (so models exist):\n",
        "\n",
        "```bash\n",
        "python -m scripts.task2_train --dataset all\n",
        "```\n",
        "\n",
        "2) Install Task 3 dependency:\n",
        "\n",
        "```bash\n",
        "pip install -r requirements-task3.txt\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Ensure repo root is on PYTHONPATH so `import src...` works in Jupyter\n",
        "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
        "\n",
        "import shap\n",
        "\n",
        "from src.modeling.task3_shap import Task3Paths, explain_task3\n",
        "\n",
        "RAW_DIR = Path(\"../data/raw\")\n",
        "REPORTS_DIR = Path(\"../reports\")\n",
        "MODELS_DIR = Path(\"../models\")\n",
        "\n",
        "paths = Task3Paths(raw_dir=RAW_DIR, reports_dir=REPORTS_DIR, models_dir=MODELS_DIR)\n",
        "\n",
        "shap.initjs()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explain Fraud_Data best model\n",
        "\n",
        "res_fraud = explain_task3(dataset=\"fraud\", paths=paths)\n",
        "res_fraud[\"model_name\"], res_fraud[\"examples\"], res_fraud[\"n_test_sample_explained\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global explanation: SHAP summary (Fraud_Data)\n",
        "\n",
        "shap.plots.beeswarm(res_fraud[\"shap_values\"], max_display=15)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Local explanations (Fraud_Data): TP / FP / FN\n",
        "\n",
        "def show_case(res, idx, title):\n",
        "    if idx is None:\n",
        "        print(f\"{title}: not found in the explained sample (try increasing explain_size)\")\n",
        "        return\n",
        "    print(title)\n",
        "    # Waterfall plot (works in most environments)\n",
        "    shap.plots.waterfall(res[\"shap_values\"][idx], max_display=15)\n",
        "\n",
        "show_case(res_fraud, res_fraud[\"examples\"][\"tp_index\"], \"True Positive (fraud correctly flagged)\")\n",
        "show_case(res_fraud, res_fraud[\"examples\"][\"fp_index\"], \"False Positive (legitimate flagged)\")\n",
        "show_case(res_fraud, res_fraud[\"examples\"][\"fn_index\"], \"False Negative (missed fraud)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explain creditcard best model\n",
        "\n",
        "res_cc = explain_task3(dataset=\"creditcard\", paths=paths)\n",
        "res_cc[\"model_name\"], res_cc[\"examples\"], res_cc[\"n_test_sample_explained\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global explanation: SHAP summary (creditcard)\n",
        "\n",
        "shap.plots.beeswarm(res_cc[\"shap_values\"], max_display=15)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Local explanations (creditcard): TP / FP / FN\n",
        "\n",
        "show_case(res_cc, res_cc[\"examples\"][\"tp_index\"], \"True Positive (fraud correctly flagged)\")\n",
        "show_case(res_cc, res_cc[\"examples\"][\"fp_index\"], \"False Positive (legitimate flagged)\")\n",
        "show_case(res_cc, res_cc[\"examples\"][\"fn_index\"], \"False Negative (missed fraud)\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
