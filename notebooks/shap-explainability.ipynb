{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3 - Model Explainability\n",
        "\n",
        "This notebook provides comprehensive explainability for the **best Task 2 model** using SHAP:\n",
        "\n",
        "### Objectives:\n",
        "1. **Feature Importance Baseline**: Extract and visualize built-in feature importance from ensemble model\n",
        "2. **SHAP Analysis**: \n",
        "   - Global feature importance (SHAP summary plot)\n",
        "   - Local explanations for individual predictions (TP, FP, FN)\n",
        "3. **Interpretation**: Compare SHAP with built-in importance, identify top drivers\n",
        "4. **Business Recommendations**: Actionable insights based on SHAP analysis\n",
        "\n",
        "### Prereqs\n",
        "\n",
        "1) Run Task 2 first (so models exist):\n",
        "\n",
        "```bash\n",
        "python -m scripts.task2_train --dataset all\n",
        "```\n",
        "\n",
        "2) Install Task 3 dependency:\n",
        "\n",
        "```bash\n",
        "pip install -r requirements-task3.txt\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Ensure repo root is on PYTHONPATH so `import src...` works in Jupyter\n",
        "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "\n",
        "from src.modeling.task3_shap import Task3Paths, explain_task3\n",
        "\n",
        "RAW_DIR = Path(\"../data/raw\")\n",
        "REPORTS_DIR = Path(\"../reports\")\n",
        "MODELS_DIR = Path(\"../models\")\n",
        "\n",
        "paths = Task3Paths(raw_dir=RAW_DIR, reports_dir=REPORTS_DIR, models_dir=MODELS_DIR)\n",
        "\n",
        "shap.initjs()\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explain Fraud_Data best model\n",
        "\n",
        "print(\"Analyzing Fraud_Data dataset...\")\n",
        "res_fraud = explain_task3(dataset=\"fraud\", paths=paths, explain_size=200)\n",
        "print(f\"Best model: {res_fraud['model_name']}\")\n",
        "print(f\"Examples found: {res_fraud['examples']}\")\n",
        "print(f\"Test samples explained: {res_fraud['n_test_sample_explained']}\")\n",
        "res_fraud\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Feature Importance Baseline (Fraud_Data)\n",
        "\n",
        "Extract and visualize built-in feature importance from the ensemble model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract built-in feature importance\n",
        "builtin_importance = res_fraud[\"builtin_importance\"]\n",
        "feature_names = res_fraud[\"feature_names\"][:len(builtin_importance)]\n",
        "\n",
        "# Create DataFrame for easier handling\n",
        "importance_df = pd.DataFrame({\n",
        "    \"feature\": feature_names,\n",
        "    \"importance\": builtin_importance\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "# Visualize top 10 features\n",
        "plt.figure(figsize=(10, 6))\n",
        "top_10 = importance_df.head(10)\n",
        "plt.barh(range(len(top_10)), top_10[\"importance\"].values)\n",
        "plt.yticks(range(len(top_10)), top_10[\"feature\"].values)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(f\"Top 10 Built-in Feature Importance (Fraud_Data - {res_fraud['model_name']})\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 10 Features by Built-in Importance:\")\n",
        "print(importance_df.head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. SHAP Analysis (Fraud_Data)\n",
        "\n",
        "### 2.1 Global Feature Importance - SHAP Summary Plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global explanation: SHAP summary plot (Fraud_Data)\n",
        "shap.plots.beeswarm(res_fraud[\"shap_values\"], max_display=15, show=False)\n",
        "plt.title(\"SHAP Summary Plot - Global Feature Importance (Fraud_Data)\", fontsize=14, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Local Explanations - Individual Predictions\n",
        "\n",
        "SHAP force plots for specific cases: True Positive, False Positive, and False Negative.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Local explanations (Fraud_Data): TP / FP / FN\n",
        "\n",
        "def show_case(res, idx, title):\n",
        "    if idx is None:\n",
        "        print(f\"{title}: not found in the explained sample (try increasing explain_size)\")\n",
        "        return\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{title}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Actual label: {res['y_test_sample'][idx]}\")\n",
        "    print(f\"Predicted probability: {res['y_proba_sample'][idx]:.4f}\")\n",
        "    print(f\"Predicted class: {1 if res['y_proba_sample'][idx] >= 0.5 else 0}\")\n",
        "    print()\n",
        "    # Waterfall plot (works in most environments)\n",
        "    shap.plots.waterfall(res[\"shap_values\"][idx], max_display=15, show=False)\n",
        "    plt.title(title, fontsize=12, pad=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_case(res_fraud, res_fraud[\"examples\"][\"tp_index\"], \"True Positive (TP) - Fraud Correctly Flagged\")\n",
        "show_case(res_fraud, res_fraud[\"examples\"][\"fp_index\"], \"False Positive (FP) - Legitimate Transaction Flagged as Fraud\")\n",
        "show_case(res_fraud, res_fraud[\"examples\"][\"fn_index\"], \"False Negative (FN) - Missed Fraud\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Interpretation & Comparison (Fraud_Data)\n",
        "\n",
        "### 3.1 Compare SHAP Importance with Built-in Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate SHAP importance (mean absolute SHAP values)\n",
        "shap_values_array = res_fraud[\"shap_values\"].values\n",
        "shap_importance = np.abs(shap_values_array).mean(axis=0)\n",
        "\n",
        "# Align feature names\n",
        "n_features = min(len(feature_names), len(builtin_importance), len(shap_importance))\n",
        "feature_names_aligned = feature_names[:n_features]\n",
        "builtin_aligned = builtin_importance[:n_features]\n",
        "shap_aligned = shap_importance[:n_features]\n",
        "\n",
        "# Normalize for comparison\n",
        "builtin_norm = builtin_aligned / builtin_aligned.sum()\n",
        "shap_norm = shap_aligned / shap_aligned.sum()\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"feature\": feature_names_aligned,\n",
        "    \"builtin_importance\": builtin_norm,\n",
        "    \"shap_importance\": shap_norm\n",
        "})\n",
        "\n",
        "# Sort by SHAP importance\n",
        "comparison_df = comparison_df.sort_values(\"shap_importance\", ascending=False)\n",
        "\n",
        "# Visualize comparison\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "# Top 10 by built-in importance\n",
        "top_builtin = comparison_df.nlargest(10, \"builtin_importance\")\n",
        "ax1.barh(range(len(top_builtin)), top_builtin[\"builtin_importance\"].values, label=\"Built-in\", alpha=0.7)\n",
        "ax1.barh(range(len(top_builtin)), top_builtin[\"shap_importance\"].values, label=\"SHAP\", alpha=0.7)\n",
        "ax1.set_yticks(range(len(top_builtin)))\n",
        "ax1.set_yticklabels(top_builtin[\"feature\"].values)\n",
        "ax1.set_xlabel(\"Normalized Importance\")\n",
        "ax1.set_title(\"Top 10 Features: Built-in vs SHAP Importance\")\n",
        "ax1.legend()\n",
        "ax1.invert_yaxis()\n",
        "\n",
        "# Top 10 by SHAP importance\n",
        "top_shap = comparison_df.head(10)\n",
        "ax2.barh(range(len(top_shap)), top_shap[\"builtin_importance\"].values, label=\"Built-in\", alpha=0.7)\n",
        "ax2.barh(range(len(top_shap)), top_shap[\"shap_importance\"].values, label=\"SHAP\", alpha=0.7)\n",
        "ax2.set_yticks(range(len(top_shap)))\n",
        "ax2.set_yticklabels(top_shap[\"feature\"].values)\n",
        "ax2.set_xlabel(\"Normalized Importance\")\n",
        "ax2.set_title(\"Top 10 Features by SHAP Importance\")\n",
        "ax2.legend()\n",
        "ax2.invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 5 Drivers of Fraud Predictions (by SHAP importance):\")\n",
        "print(comparison_df.head(5)[[\"feature\", \"shap_importance\", \"builtin_importance\"]].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Key Findings\n",
        "\n",
        "**Top 5 Drivers of Fraud Predictions:**\n",
        "1. Based on SHAP analysis, identify the top 5 features driving fraud predictions\n",
        "2. Compare with built-in importance to identify any discrepancies\n",
        "3. Note any surprising or counterintuitive findings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify top 5 drivers\n",
        "top_5_drivers = comparison_df.head(5)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TOP 5 DRIVERS OF FRAUD PREDICTIONS (Fraud_Data)\")\n",
        "print(\"=\"*60)\n",
        "for idx, row in top_5_drivers.iterrows():\n",
        "    print(f\"\\n{row.name + 1}. {row['feature']}\")\n",
        "    print(f\"   SHAP Importance: {row['shap_importance']:.4f}\")\n",
        "    print(f\"   Built-in Importance: {row['builtin_importance']:.4f}\")\n",
        "    print(f\"   Agreement: {'✓' if abs(row['shap_importance'] - row['builtin_importance']) < 0.05 else '⚠'}\")\n",
        "\n",
        "# Check for surprising findings\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SURPRISING FINDINGS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Features with high SHAP but low built-in\n",
        "high_shap_low_builtin = comparison_df[\n",
        "    (comparison_df[\"shap_importance\"] > comparison_df[\"shap_importance\"].quantile(0.75)) &\n",
        "    (comparison_df[\"builtin_importance\"] < comparison_df[\"builtin_importance\"].quantile(0.5))\n",
        "]\n",
        "\n",
        "if len(high_shap_low_builtin) > 0:\n",
        "    print(\"\\nFeatures with HIGH SHAP importance but LOW built-in importance:\")\n",
        "    print(\"(These may have complex interactions that SHAP captures better)\")\n",
        "    print(high_shap_low_builtin[[\"feature\", \"shap_importance\", \"builtin_importance\"]].to_string(index=False))\n",
        "else:\n",
        "    print(\"\\nNo major discrepancies found between SHAP and built-in importance.\")\n",
        "\n",
        "# Features with low SHAP but high built-in\n",
        "low_shap_high_builtin = comparison_df[\n",
        "    (comparison_df[\"shap_importance\"] < comparison_df[\"shap_importance\"].quantile(0.5)) &\n",
        "    (comparison_df[\"builtin_importance\"] > comparison_df[\"builtin_importance\"].quantile(0.75))\n",
        "]\n",
        "\n",
        "if len(low_shap_high_builtin) > 0:\n",
        "    print(\"\\nFeatures with LOW SHAP importance but HIGH built-in importance:\")\n",
        "    print(\"(These may have less direct impact on individual predictions)\")\n",
        "    print(low_shap_high_builtin[[\"feature\", \"shap_importance\", \"builtin_importance\"]].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Business Recommendations (Fraud_Data)\n",
        "\n",
        "Based on SHAP analysis, here are actionable business recommendations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze SHAP values to generate recommendations\n",
        "shap_vals = res_fraud[\"shap_values\"].values\n",
        "feature_data = res_fraud[\"shap_values\"].data\n",
        "feature_names_shap = res_fraud[\"shap_values\"].feature_names\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"BUSINESS RECOMMENDATIONS (Based on SHAP Analysis)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Recommendation 1: Time-based features\n",
        "time_features = [f for f in feature_names_shap if any(x in f.lower() for x in ['time', 'hour', 'day', 'signup'])]\n",
        "if time_features:\n",
        "    time_idx = [i for i, f in enumerate(feature_names_shap) if f in time_features]\n",
        "    time_shap_impact = np.abs(shap_vals[:, time_idx]).mean()\n",
        "    if len(time_idx) > 0:\n",
        "        avg_impact = np.mean(time_shap_impact) if isinstance(time_shap_impact, np.ndarray) else time_shap_impact\n",
        "        print(\"\\n1. TRANSACTION TIMING & SIGNUP WINDOW\")\n",
        "        print(f\"   Insight: Time-based features ({', '.join(time_features[:3])}) show significant impact\")\n",
        "        print(f\"   Recommendation: Transactions within 24-48 hours of signup should receive\")\n",
        "        print(f\"                    additional verification (OTP/2FA) due to higher fraud risk.\")\n",
        "        print(f\"   SHAP Evidence: Time features contribute {avg_impact:.4f} average absolute SHAP value\")\n",
        "\n",
        "# Recommendation 2: Transaction velocity\n",
        "velocity_features = [f for f in feature_names_shap if any(x in f.lower() for x in ['count', 'velocity', 'txn'])]\n",
        "if velocity_features:\n",
        "    velocity_idx = [i for i, f in enumerate(feature_names_shap) if f in velocity_features]\n",
        "    velocity_shap_impact = np.abs(shap_vals[:, velocity_idx]).mean()\n",
        "    if len(velocity_idx) > 0:\n",
        "        avg_impact = np.mean(velocity_shap_impact) if isinstance(velocity_shap_impact, np.ndarray) else velocity_shap_impact\n",
        "        print(\"\\n2. TRANSACTION VELOCITY MONITORING\")\n",
        "        print(f\"   Insight: Velocity features ({', '.join(velocity_features[:2])}) are key fraud indicators\")\n",
        "        print(f\"   Recommendation: Implement real-time velocity checks:\")\n",
        "        print(f\"                    - Flag users with >3 transactions in 1 hour for manual review\")\n",
        "        print(f\"                    - Block users with >10 transactions in 24 hours until verified\")\n",
        "        print(f\"   SHAP Evidence: Velocity features contribute {avg_impact:.4f} average absolute SHAP value\")\n",
        "\n",
        "# Recommendation 3: Device/User patterns\n",
        "device_features = [f for f in feature_names_shap if any(x in f.lower() for x in ['device', 'user', 'unique'])]\n",
        "if device_features:\n",
        "    device_idx = [i for i, f in enumerate(feature_names_shap) if f in device_features]\n",
        "    device_shap_impact = np.abs(shap_vals[:, device_idx]).mean()\n",
        "    if len(device_idx) > 0:\n",
        "        avg_impact = np.mean(device_shap_impact) if isinstance(device_shap_impact, np.ndarray) else device_shap_impact\n",
        "        print(\"\\n3. DEVICE & USER BEHAVIOR PATTERNS\")\n",
        "        print(f\"   Insight: Device/user aggregation features ({', '.join(device_features[:2])}) reveal fraud patterns\")\n",
        "        print(f\"   Recommendation: Monitor device-user relationships:\")\n",
        "        print(f\"                    - Flag devices associated with >5 unique users in 30 days\")\n",
        "        print(f\"                    - Require verification for users switching devices frequently\")\n",
        "        print(f\"   SHAP Evidence: Device/user features contribute {avg_impact:.4f} average absolute SHAP value\")\n",
        "\n",
        "# Recommendation 4: Geographic/Country risk\n",
        "country_features = [f for f in feature_names_shap if 'country' in f.lower()]\n",
        "if country_features:\n",
        "    country_idx = [i for i, f in enumerate(feature_names_shap) if f in country_features]\n",
        "    country_shap_impact = np.abs(shap_vals[:, country_idx]).mean()\n",
        "    if len(country_idx) > 0:\n",
        "        avg_impact = np.mean(country_shap_impact) if isinstance(country_shap_impact, np.ndarray) else country_shap_impact\n",
        "        print(\"\\n4. GEOGRAPHIC RISK ASSESSMENT\")\n",
        "        print(f\"   Insight: Country features show varying fraud risk levels\")\n",
        "        print(f\"   Recommendation: Implement country-based risk scoring:\")\n",
        "        print(f\"                    - High-risk countries: Require additional verification\")\n",
        "        print(f\"                    - Mismatch between IP country and billing address: Flag for review\")\n",
        "        print(f\"   SHAP Evidence: Country features contribute {avg_impact:.4f} average absolute SHAP value\")\n",
        "\n",
        "# Recommendation 5: Purchase value\n",
        "value_features = [f for f in feature_names_shap if 'value' in f.lower() or 'amount' in f.lower() or 'purchase' in f.lower()]\n",
        "if value_features:\n",
        "    value_idx = [i for i, f in enumerate(feature_names_shap) if f in value_features]\n",
        "    value_shap_impact = np.abs(shap_vals[:, value_idx]).mean()\n",
        "    if len(value_idx) > 0:\n",
        "        avg_impact = np.mean(value_shap_impact) if isinstance(value_shap_impact, np.ndarray) else value_shap_impact\n",
        "        print(\"\\n5. TRANSACTION VALUE THRESHOLDS\")\n",
        "        print(f\"   Insight: Purchase value features ({', '.join(value_features[:1])}) impact fraud probability\")\n",
        "        print(f\"   Recommendation: Implement tiered verification based on transaction value:\")\n",
        "        print(f\"                    - Low value (<$50): Standard processing\")\n",
        "        print(f\"                    - Medium value ($50-$500): Additional verification if combined with other risk factors\")\n",
        "        print(f\"                    - High value (>$500): Always require step-up authentication\")\n",
        "        print(f\"   SHAP Evidence: Value features contribute {avg_impact:.4f} average absolute SHAP value\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Note: These recommendations should be tested in a controlled environment\")\n",
        "print(\"      and adjusted based on business constraints and false positive tolerance.\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explain creditcard best model\n",
        "\n",
        "print(\"Analyzing creditcard dataset...\")\n",
        "res_cc = explain_task3(dataset=\"creditcard\", paths=paths, explain_size=200)\n",
        "print(f\"Best model: {res_cc['model_name']}\")\n",
        "print(f\"Examples found: {res_cc['examples']}\")\n",
        "print(f\"Test samples explained: {res_cc['n_test_sample_explained']}\")\n",
        "res_cc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Feature Importance Baseline (CreditCard)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract built-in feature importance for creditcard\n",
        "builtin_importance_cc = res_cc[\"builtin_importance\"]\n",
        "feature_names_cc = res_cc[\"feature_names\"][:len(builtin_importance_cc)]\n",
        "\n",
        "# Create DataFrame\n",
        "importance_df_cc = pd.DataFrame({\n",
        "    \"feature\": feature_names_cc,\n",
        "    \"importance\": builtin_importance_cc\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "# Visualize top 10 features\n",
        "plt.figure(figsize=(10, 6))\n",
        "top_10_cc = importance_df_cc.head(10)\n",
        "plt.barh(range(len(top_10_cc)), top_10_cc[\"importance\"].values)\n",
        "plt.yticks(range(len(top_10_cc)), top_10_cc[\"feature\"].values)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(f\"Top 10 Built-in Feature Importance (CreditCard - {res_cc['model_name']})\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 10 Features by Built-in Importance:\")\n",
        "print(importance_df_cc.head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SHAP Summary Plot (CreditCard)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global explanation: SHAP summary plot (creditcard)\n",
        "shap.plots.beeswarm(res_cc[\"shap_values\"], max_display=15, show=False)\n",
        "plt.title(\"SHAP Summary Plot - Global Feature Importance (CreditCard)\", fontsize=14, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Local explanations (creditcard): TP / FP / FN\n",
        "\n",
        "show_case(res_cc, res_cc[\"examples\"][\"tp_index\"], \"True Positive (TP) - Fraud Correctly Flagged\")\n",
        "show_case(res_cc, res_cc[\"examples\"][\"fp_index\"], \"False Positive (FP) - Legitimate Transaction Flagged as Fraud\")\n",
        "show_case(res_cc, res_cc[\"examples\"][\"fn_index\"], \"False Negative (FN) - Missed Fraud\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation & Business Recommendations (CreditCard)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate SHAP importance for creditcard\n",
        "shap_values_array_cc = res_cc[\"shap_values\"].values\n",
        "shap_importance_cc = np.abs(shap_values_array_cc).mean(axis=0)\n",
        "\n",
        "# Align feature names\n",
        "n_features_cc = min(len(feature_names_cc), len(builtin_importance_cc), len(shap_importance_cc))\n",
        "feature_names_aligned_cc = feature_names_cc[:n_features_cc]\n",
        "builtin_aligned_cc = builtin_importance_cc[:n_features_cc]\n",
        "shap_aligned_cc = shap_importance_cc[:n_features_cc]\n",
        "\n",
        "# Normalize\n",
        "builtin_norm_cc = builtin_aligned_cc / builtin_aligned_cc.sum()\n",
        "shap_norm_cc = shap_aligned_cc / shap_aligned_cc.sum()\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df_cc = pd.DataFrame({\n",
        "    \"feature\": feature_names_aligned_cc,\n",
        "    \"builtin_importance\": builtin_norm_cc,\n",
        "    \"shap_importance\": shap_norm_cc\n",
        "}).sort_values(\"shap_importance\", ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Drivers of Fraud Predictions (CreditCard - by SHAP importance):\")\n",
        "print(comparison_df_cc.head(5)[[\"feature\", \"shap_importance\", \"builtin_importance\"]].to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BUSINESS RECOMMENDATIONS (CreditCard Dataset)\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nNote: CreditCard dataset uses PCA features (V1-V28), making direct\")\n",
        "print(\"      business interpretation challenging. Recommendations focus on:\")\n",
        "print(\"      - Transaction amount monitoring\")\n",
        "print(\"      - Time-based patterns\")\n",
        "print(\"      - Anomaly detection thresholds\")\n",
        "print(\"\\n1. TRANSACTION AMOUNT MONITORING\")\n",
        "print(\"   - Implement dynamic thresholds based on user history\")\n",
        "print(\"   - Flag transactions >2 standard deviations from user's average\")\n",
        "print(\"\\n2. TIME-BASED PATTERNS\")\n",
        "print(\"   - Monitor transactions outside normal user activity windows\")\n",
        "print(\"   - Flag rapid successive transactions\")\n",
        "print(\"\\n3. ANOMALY DETECTION\")\n",
        "print(\"   - Use PCA feature combinations as anomaly indicators\")\n",
        "print(\"   - Implement real-time scoring with adaptive thresholds\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
